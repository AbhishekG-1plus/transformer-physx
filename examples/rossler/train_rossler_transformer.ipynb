{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_rossler_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "75HXWsO0huoc",
        "rKUsluH6h48P",
        "nE__niItjdkM",
        "ZnuHqNRCiC4n"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPjTnCG-v2Z6",
        "outputId": "c547a035-473d-4820-b799-3b20fdd8fc14"
      },
      "source": [
        "\"\"\"\n",
        "Notebook for training the transformer model for the Rossler system.\n",
        "=====\n",
        "Distributed by: Notre Dame SCAI Lab (MIT Liscense)\n",
        "- Associated publication:\n",
        "url: https://arxiv.org/abs/2010.03957\n",
        "doi: \n",
        "github: https://github.com/zabaras/transformer-physx\n",
        "=====\n",
        "\"\"\"\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 28 23:57:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCxpDBPVPdq"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adPNHn3_Q25_"
      },
      "source": [
        "Use pip to install from [PyPI](https://pypi.org/project/trphysx/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvm518_H3AK7",
        "outputId": "b7c5b516-2f7a-46ef-b317-5bd6a8da8941"
      },
      "source": [
        "!pip install trphysx==0.0.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trphysx==0.0.7\n",
            "  Downloading trphysx-0.0.7-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 102 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 112 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 137 kB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from trphysx==0.0.7) (1.9.0+cu102)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->trphysx==0.0.7) (1.5.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->trphysx==0.0.7) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (3.7.4.3)\n",
            "Installing collected packages: trphysx\n",
            "Successfully installed trphysx-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoBoGx0J0LtZ"
      },
      "source": [
        "First mount google drive and clone transformer physx repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K0hSst0b2Ak",
        "outputId": "48f35efb-b3ec-4231-db21-d9b107b1a04d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJL720VLw46q",
        "outputId": "f853f1a1-10c4-4223-b74e-1bb231a12d70"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/\n",
        "% mkdir -p transformer_physx/rossler\n",
        "% cd transformer_physx/rossler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive/transformer_physx/rossler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlsHPvFNVUnQ"
      },
      "source": [
        "## Downloading Data and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MK_h8wF0Rr4"
      },
      "source": [
        "Now lets download the training and validation data for the Rossler system. Info on wget from [Google drive](https://stackoverflow.com/questions/37453841/download-a-file-from-google-drive-using-wget). This will eventually be update to zenodo repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NtZ02zD0EKo",
        "outputId": "01ab1bc3-5dbe-47a8-dda1-8a6a8a18e16a"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU702uo6xIQQ",
        "outputId": "f39304f8-2e1b-4917-8b3b-77efedcff6f5"
      },
      "source": [
        "!wget -O ./data/rossler_training.hdf5 \"https://drive.google.com/uc?export=download&id=1eEXYbiZEz5rlEBoF3erDA_sqNWP0AFtp\"\n",
        "!wget -O ./data/rossler_valid.hdf5 \"https://drive.google.com/uc?export=download&id=1LSCmkeM2Z6n8f5bzTkx50YuZvcL2WLsk\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-28 23:54:58--  https://drive.google.com/uc?export=download&id=1eEXYbiZEz5rlEBoF3erDA_sqNWP0AFtp\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.188.206, 2607:f8b0:4004:836::200e\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.188.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cdhm0jshd82r5kic9jg19hpebs2ccbf4/1627516425000/01559412990587423567/*/1eEXYbiZEz5rlEBoF3erDA_sqNWP0AFtp?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-28 23:54:58--  https://doc-0k-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cdhm0jshd82r5kic9jg19hpebs2ccbf4/1627516425000/01559412990587423567/*/1eEXYbiZEz5rlEBoF3erDA_sqNWP0AFtp?e=download\n",
            "Resolving doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)... 142.250.188.193, 2607:f8b0:4004:836::2001\n",
            "Connecting to doc-0k-0o-docs.googleusercontent.com (doc-0k-0o-docs.googleusercontent.com)|142.250.188.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-hdf]\n",
            "Saving to: ‘./data/rossler_training.hdf5’\n",
            "\n",
            "./data/rossler_trai     [ <=>                ]   6.10M  33.6MB/s    in 0.2s    \n",
            "\n",
            "2021-07-28 23:54:58 (33.6 MB/s) - ‘./data/rossler_training.hdf5’ saved [6396672]\n",
            "\n",
            "--2021-07-28 23:54:59--  https://drive.google.com/uc?export=download&id=1LSCmkeM2Z6n8f5bzTkx50YuZvcL2WLsk\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.188.206, 2607:f8b0:4004:836::200e\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.188.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ct63eco7rrt50r1oe44crbcbl0q0ss2m/1627516425000/01559412990587423567/*/1LSCmkeM2Z6n8f5bzTkx50YuZvcL2WLsk?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-28 23:54:59--  https://doc-00-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ct63eco7rrt50r1oe44crbcbl0q0ss2m/1627516425000/01559412990587423567/*/1LSCmkeM2Z6n8f5bzTkx50YuZvcL2WLsk?e=download\n",
            "Resolving doc-00-0o-docs.googleusercontent.com (doc-00-0o-docs.googleusercontent.com)... 142.250.188.193, 2607:f8b0:4004:836::2001\n",
            "Connecting to doc-00-0o-docs.googleusercontent.com (doc-00-0o-docs.googleusercontent.com)|142.250.188.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 799488 (781K) [application/x-hdf]\n",
            "Saving to: ‘./data/rossler_valid.hdf5’\n",
            "\n",
            "./data/rossler_vali 100%[===================>] 780.75K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-07-28 23:54:59 (11.7 MB/s) - ‘./data/rossler_valid.hdf5’ saved [799488/799488]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vKlS8OF-aoT"
      },
      "source": [
        "Next lets download a pretrained embedding model. You can replace with with your own if you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNZkweD0-hu1",
        "outputId": "d3e20f52-d5e2-4200-8f95-dd4221b8889c"
      },
      "source": [
        "!wget -O ./embedding_rossler300.pth \"https://drive.google.com/uc?export=download&id=1V0MMh8dm5E8OiZTc8xMaiAjjcswdP1nL\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-28 22:48:51--  https://drive.google.com/uc?export=download&id=1V0MMh8dm5E8OiZTc8xMaiAjjcswdP1nL\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.2.101, 142.251.2.102, 142.251.2.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.2.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-00-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3s0pvjfflhmq8cc92a3durc6bvo3vlog/1627512525000/01559412990587423567/*/1V0MMh8dm5E8OiZTc8xMaiAjjcswdP1nL?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-28 22:48:52--  https://doc-00-0o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3s0pvjfflhmq8cc92a3durc6bvo3vlog/1627512525000/01559412990587423567/*/1V0MMh8dm5E8OiZTc8xMaiAjjcswdP1nL?e=download\n",
            "Resolving doc-00-0o-docs.googleusercontent.com (doc-00-0o-docs.googleusercontent.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to doc-00-0o-docs.googleusercontent.com (doc-00-0o-docs.googleusercontent.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147407 (144K) [application/octet-stream]\n",
            "Saving to: ‘./embedding_rossler300.pth’\n",
            "\n",
            "./embedding_rossler 100%[===================>] 143.95K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-07-28 22:48:52 (1.62 MB/s) - ‘./embedding_rossler300.pth’ saved [147407/147407]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgRznlNJVH0Y"
      },
      "source": [
        "# Transformer-PhysX Rossler System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDVeeJHn11Ir"
      },
      "source": [
        "The Rossler system is **not** a prebuilt example in trphysx thus we need to create four classes for our numerical example:\n",
        "- *Config class* - Embedding and mainly transformer architecture parameters\n",
        "- *Embedding class* - Convert states into embedding vector\n",
        "- *Visualization class* - Visualize predictions\n",
        "- *Transformer dataset class* - Create dataset for training\n",
        "\n",
        "Fortunately trphysx has base classes for all of these that contain both useful methods and as well as abstract declarations to help guide you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNGVZQ-o1gsH"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "# Torch imports\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "# Trphysx imports\n",
        "from trphysx.config import HfArgumentParser\n",
        "from trphysx.config.args import ModelArguments, TrainingArguments, DataArguments, ArgUtils\n",
        "from trphysx.embedding import EmbeddingModel\n",
        "from trphysx.config.configuration_phys import PhysConfig\n",
        "from trphysx.data_utils.dataset_phys import PhysicalDataset\n",
        "from trphysx.transformer import PhysformerTrain, PhysformerGPT2\n",
        "from trphysx.utils.trainer import Trainer\n",
        "\n",
        "Tensor = torch.Tensor\n",
        "TensorTuple = Tuple[torch.Tensor]\n",
        "FloatTuple = Tuple[float]\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEft0ltg4swx"
      },
      "source": [
        "Set training arguments. For running this outside of a notebook, you would use \"sys.argv\" and then no argument when you parse args into dataclasses. This would allow the use of command line parameters as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R8QQ0cj4qR9"
      },
      "source": [
        "argv = []\n",
        "argv = argv + [\"--init_name\", \"rossler\"]\n",
        "argv = argv + [\"--embedding_file_or_path\", \"./embedding_rossler300.pth\"]\n",
        "argv = argv + [\"--training_h5_file\",\"./data/rossler_training.hdf5\"]\n",
        "argv = argv + [\"--eval_h5_file\",\"./data/rossler_valid.hdf5\"]\n",
        "argv = argv + [\"--train_batch_size\", \"64\"]\n",
        "argv = argv + [\"--stride\", \"16\"]\n",
        "argv = argv + [\"--n_train\", \"2048\"]\n",
        "argv = argv + [\"--n_eval\", \"32\"]\n",
        "argv = argv + [\"--save_steps\", \"25\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75HXWsO0huoc"
      },
      "source": [
        "## Rossler Config Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EoTZ2Gthyuj"
      },
      "source": [
        "class RosslerConfig(PhysConfig):\n",
        "    \"\"\"\n",
        "    This is the configuration class for the modeling of the Rossler system.\n",
        "    \"\"\"\n",
        "\n",
        "    model_type = \"rossler\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_ctx=32,\n",
        "        n_embd=32,\n",
        "        n_layer=4,\n",
        "        n_head=4, # n_head must be a factor of n_embd\n",
        "        state_dims=[3],\n",
        "        activation_function=\"gelu_new\",\n",
        "        initializer_range=0.02,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            n_ctx=n_ctx,\n",
        "            n_embd=n_embd,\n",
        "            n_layer=n_layer,\n",
        "            n_head=n_head,\n",
        "            state_dims=state_dims,\n",
        "            activation_function=activation_function,\n",
        "            initializer_range=initializer_range,\n",
        "            **kwargs\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKUsluH6h48P"
      },
      "source": [
        "## Embedding Neural Network Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hHxgYUTmRxH"
      },
      "source": [
        "Note here that we only need a subset of the methods needed for training the embedding model namely we just need \"embed\" and \"recover\" methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quAIE8Zgh-gF"
      },
      "source": [
        "class RosslerEmbedding(EmbeddingModel):\n",
        "    \"\"\"Embedding model for the Rossler ODE system\n",
        "\n",
        "    Args:\n",
        "        config (PhysConfig) Configuration class with transformer/embedding parameters\n",
        "    \"\"\"\n",
        "    model_name = \"embedding_rossler\"\n",
        "\n",
        "    def __init__(self, config: PhysConfig) -> None:\n",
        "        \"\"\"Constructor method\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "\n",
        "        hidden_states = int(abs(config.state_dims[0] - config.n_embd)/2) + 1\n",
        "        hidden_states = 500\n",
        "\n",
        "        self.observableNet = nn.Sequential(\n",
        "            nn.Linear(config.state_dims[0], hidden_states),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_states, config.n_embd),\n",
        "            nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon),\n",
        "            nn.Dropout(config.embd_pdrop)\n",
        "        )\n",
        "\n",
        "        self.recoveryNet = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, hidden_states),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_states, config.state_dims[0])\n",
        "        )\n",
        "        # Learned koopman operator\n",
        "        # Learns skew-symmetric matrix with a diagonal\n",
        "        self.obsdim = config.n_embd\n",
        "        self.kMatrixDiag = nn.Parameter(torch.linspace(1, 0, config.n_embd))\n",
        "\n",
        "        xidx = []\n",
        "        yidx = []\n",
        "        for i in range(1, 5):\n",
        "            yidx.append(np.arange(i, config.n_embd))\n",
        "            xidx.append(np.arange(0, config.n_embd-i))\n",
        "\n",
        "        self.xidx = torch.LongTensor(np.concatenate(xidx))\n",
        "        self.yidx = torch.LongTensor(np.concatenate(yidx))\n",
        "        self.kMatrixUT = nn.Parameter(0.1*torch.rand(self.xidx.size(0)))\n",
        "        # Normalization occurs inside the model\n",
        "        self.register_buffer('mu', torch.tensor([0., 0., 0.]))\n",
        "        self.register_buffer('std', torch.tensor([1., 1., 1.]))\n",
        "        print('Number of embedding parameters: {}'.format( super().num_parameters ))\n",
        "\n",
        "    def embed(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Embeds tensor of state variables to Koopman observables\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): [B, 3] input feature tensor\n",
        "\n",
        "        Returns:\n",
        "            (Tensor): [B, config.n_embd] Koopman observables\n",
        "        \"\"\"\n",
        "        x = self._normalize(x)\n",
        "        g = self.observableNet(x)\n",
        "        return g\n",
        "\n",
        "    def recover(self, g: Tensor) -> Tensor:\n",
        "        \"\"\"Recovers feature tensor from Koopman observables\n",
        "\n",
        "        Args:\n",
        "            g (Tensor): [B, config.n_embd] Koopman observables\n",
        "\n",
        "        Returns:\n",
        "            (Tensor): [B, 3] Physical feature tensor\n",
        "        \"\"\"\n",
        "        out = self.recoveryNet(g)\n",
        "        x = self._unnormalize(out)\n",
        "        return x\n",
        "\n",
        "    def _normalize(self, x: Tensor) -> Tensor:\n",
        "        return (x - self.mu.unsqueeze(0))/self.std.unsqueeze(0)\n",
        "\n",
        "    def _unnormalize(self, x: Tensor) -> Tensor:\n",
        "        return self.std.unsqueeze(0)*x + self.mu.unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE__niItjdkM"
      },
      "source": [
        "## Rossler Visualization Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEpJyca8jge5"
      },
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.legend_handler import HandlerBase\n",
        "from trphysx.viz import Viz\n",
        "\n",
        "# Interface to LineCollection:\n",
        "def _colorline3d(x, y, z, t=None, cmap=plt.get_cmap('viridis'), linewidth=1, alpha=1.0, ax=None):\n",
        "    '''\n",
        "    Plot a colored line with coordinates x and y\n",
        "    Optionally specify colors in the array z\n",
        "    Optionally specify a colormap, a norm function and a line width\n",
        "    https://stackoverflow.com/questions/52884221/how-to-plot-a-matplotlib-line-plot-using-colormap\n",
        "    '''\n",
        "    # Default colors equally spaced on [0,1]:\n",
        "    if t is None:\n",
        "        t = np.linspace(0.25, 1.0, len(x))\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    points = np.array([x, y, z]).T.reshape(-1, 1, 3)\n",
        "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
        "\n",
        "    colors = np.array([cmap(i) for i in t])\n",
        "    lc = Line3DCollection(segments, colors=colors, linewidth=linewidth,  alpha=alpha)\n",
        "    ax.add_collection(lc)\n",
        "    ax.scatter(x, y, z, c=colors, marker='*', alpha=alpha) #Adding line markers\n",
        "\n",
        "class HandlerColormap(HandlerBase):\n",
        "    def __init__(self, cmap, num_stripes=8, **kw):\n",
        "        HandlerBase.__init__(self, **kw)\n",
        "        self.cmap = cmap\n",
        "        self.num_stripes = num_stripes\n",
        "    def create_artists(self, legend, orig_handle,\n",
        "                       xdescent, ydescent, width, height, fontsize, trans):\n",
        "        stripes = []\n",
        "        for i in range(self.num_stripes):\n",
        "            s = Rectangle([xdescent + i * width / self.num_stripes, ydescent],\n",
        "                          width / self.num_stripes,\n",
        "                          height,\n",
        "                          fc=self.cmap((2 * i + 1) / (2 * self.num_stripes)),\n",
        "                          transform=trans)\n",
        "            stripes.append(s)\n",
        "        return stripes\n",
        "\n",
        "class RosslerViz(Viz):\n",
        "    \"\"\"Visualization class for Rosler ODE\n",
        "\n",
        "    Args:\n",
        "        plot_dir (str, optional): Directory to save visualizations in. Defaults to None.\n",
        "    \"\"\"\n",
        "    def __init__(self, plot_dir:str = None) -> None:\n",
        "        super().__init__(plot_dir=plot_dir)\n",
        "\n",
        "    def plotPrediction(self,\n",
        "        y_pred: Tensor,\n",
        "        y_target: Tensor,\n",
        "        plot_dir: str = None,\n",
        "        epoch: int = None,\n",
        "        pid: int = 0,\n",
        "        nsteps: int = 256\n",
        "    ) -> None:\n",
        "        \"\"\"Plots a 3D line of a single Rossler prediction\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): [T, 3] Prediction tensor.\n",
        "            y_target (Tensor): [T, 3] Target tensor.\n",
        "            plot_dir (str, optional): Directory to save figure, overrides plot_dir one if provided. Defaults to None.\n",
        "            epoch (int, optional): Current epoch, used for file name. Defaults to None.\n",
        "            pid (int, optional): Optional plotting id for indexing file name manually. Defaults to 0.\n",
        "            nsteps (int, optional): Number of steps to plot. Defaults to 256.\n",
        "        \"\"\"\n",
        "        # Convert to numpy array\n",
        "        y_pred = y_pred[:nsteps].detach().cpu().numpy()\n",
        "        y_target = y_target[:nsteps].detach().cpu().numpy()\n",
        "\n",
        "        plt.close('all')\n",
        "        mpl.rcParams['font.family'] = ['serif'] # default is sans-serif\n",
        "        mpl.rcParams['figure.dpi'] = 300\n",
        "        # rc('text', usetex=True)\n",
        "        # Set up figure\n",
        "        fig = plt.figure(figsize=(10, 10))\n",
        "        ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "        cmaps = [plt.get_cmap(\"Reds\"), plt.get_cmap(\"Blues\")]\n",
        "        _colorline3d(y_pred[:,0], y_pred[:,1], y_pred[:,2], cmap=cmaps[0], ax=ax)\n",
        "        _colorline3d(y_target[:,0], y_target[:,1], y_target[:,2], cmap=cmaps[1], ax=ax)\n",
        "\n",
        "        ax.set_xlim([np.amin(y_target[:,0])-5, np.amax(y_target[:,0])+5])\n",
        "        ax.set_ylim([np.amin(y_target[:,1])-5, np.amax(y_target[:,1])+5])\n",
        "        ax.set_zlim([np.amin(y_target[:,2])-5, np.amax(y_target[:,2])+5])\n",
        "\n",
        "        cmap_handles = [Rectangle((0, 0), 1, 1) for _ in cmaps]\n",
        "        handler_map = dict(zip(cmap_handles,\n",
        "                            [HandlerColormap(cm, num_stripes=8) for cm in cmaps]))\n",
        "        # Create custom legend with color map rectangels\n",
        "        ax.legend(handles=cmap_handles, labels=['Prediction','Target'], handler_map=handler_map, loc='upper right', framealpha=0.95)\n",
        "\n",
        "        if(not epoch is None):\n",
        "            file_name = 'rosslerPred{:d}_{:d}'.format(pid, epoch)\n",
        "        else:\n",
        "            file_name = 'rosslerPred{:d}'.format(pid)\n",
        "\n",
        "        self.saveFigure(plot_dir, file_name)\n",
        "\n",
        "    def plotMultiPrediction(self,\n",
        "        y_pred: Tensor,\n",
        "        y_target: Tensor,\n",
        "        plot_dir: str = None,\n",
        "        epoch: int = None,\n",
        "        pid: int = 0,\n",
        "        nplots: int = 2\n",
        "    ) -> None:\n",
        "        \"\"\"Plots the 3D lines of multiple Lorenz predictions\n",
        "\n",
        "        Args:\n",
        "            y_pred (Tensor): [T, 3] Prediction tensor.\n",
        "            y_target (Tensor): [T, 3] Target tensor.\n",
        "            plot_dir (str, optional): Directory to save figure, overrides plot_dir one if provided. Defaults to None.\n",
        "            epoch (int, optional): Current epoch, used for file name. Defaults to None.\n",
        "            pid (int, optional): Optional plotting id for indexing file name manually, Defaults to 0.\n",
        "            nplots (int, optional): Number of cases to plot, Defaults to 2.\n",
        "        \"\"\"\n",
        "        assert y_pred.size(0) >= nplots, 'Number of provided predictions is less than the requested number of subplots'\n",
        "        assert y_target.size(0) >= nplots, 'Number of provided targets is less than the requested number of subplots'\n",
        "        # Convert to numpy array\n",
        "        y_pred = y_pred.detach().cpu().numpy()\n",
        "        y_target = y_target.detach().cpu().numpy()\n",
        "\n",
        "        plt.close('all')\n",
        "        mpl.rcParams['font.family'] = ['serif']  # default is sans-serif\n",
        "        mpl.rcParams['figure.dpi'] = 300\n",
        "        # rc('text', usetex=True)\n",
        "        # Set up figure\n",
        "        fig, ax = plt.subplots(1, nplots, figsize=(6*nplots, 6), subplot_kw={'projection': '3d'})\n",
        "        plt.subplots_adjust(wspace=0.025)\n",
        "\n",
        "        cmaps = [plt.get_cmap(\"Reds\"), plt.get_cmap(\"Blues\")]\n",
        "        for i in range(nplots):\n",
        "            _colorline3d(y_pred[i, :, 0], y_pred[i, :, 1], y_pred[i, :, 2], cmap=cmaps[0], ax=ax[i], alpha=0.6)\n",
        "            _colorline3d(y_target[i, :, 0], y_target[i, :, 1], y_target[i, :, 2], cmap=cmaps[1], ax=ax[i], alpha=0.6)\n",
        "\n",
        "            ax[i].set_xlim([np.amin(y_target[:,0])-5, np.amax(y_target[:,0])+5])\n",
        "            ax[i].set_ylim([np.amin(y_target[:,1])-5, np.amax(y_target[:,1])+5])\n",
        "            ax[i].set_zlim([np.amin(y_target[:,2])-5, np.amax(y_target[:,2])+5])\n",
        "\n",
        "            ax[i].set_xlabel('x', fontsize=14)\n",
        "            ax[i].set_ylabel('y', fontsize=14)\n",
        "            ax[i].set_zlabel('z', fontsize=14)\n",
        "        cmap_handles = [Rectangle((0, 0), 1, 1) for _ in cmaps]\n",
        "        handler_map = dict(zip(cmap_handles,\n",
        "                               [HandlerColormap(cm, num_stripes=10) for cm in cmaps]))\n",
        "\n",
        "        # Create custom legend with color map rectangels\n",
        "        ax[-1].legend(handles=cmap_handles, labels=['Prediction', 'Target'], handler_map=handler_map, loc='upper right',\n",
        "                  framealpha=0.95)\n",
        "\n",
        "        if epoch is not None:\n",
        "            file_name = 'rosslerMultiPred{:d}_{:d}'.format(pid, epoch)\n",
        "        else:\n",
        "            file_name = 'rosslerMultiPred{:d}'.format(pid)\n",
        "\n",
        "        self.saveFigure(plot_dir, file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnuHqNRCiC4n"
      },
      "source": [
        "## Transformer Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAzXd6HSmgxY"
      },
      "source": [
        "Similar to the  built in examples to create a data-set for a physics transformer the \"embed_data\" method needs to be overloaded which tells trphysx how to transformer states into an embedded vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G90ZHyNiOTX"
      },
      "source": [
        "class RosslerDataset(PhysicalDataset):\n",
        "    \"\"\"Dataset for the Rossler numerical example\n",
        "    \"\"\"\n",
        "    def embed_data(self, h5_file: h5py.File, embedder: EmbeddingModel) -> None:\n",
        "        \"\"\"Embeds rossler data into a 1D vector representation for the transformer.\n",
        "\n",
        "        Args:\n",
        "            h5_file (h5py.File): HDF5 file object of raw data\n",
        "            embedder (EmbeddingModel): Embedding neural network\n",
        "        \"\"\"\n",
        "        # Iterate through stored time-series\n",
        "        samples = 0\n",
        "        for key in h5_file.keys():\n",
        "            data_series = torch.Tensor(h5_file[key]).to(embedder.devices[0]).view([-1] + embedder.input_dims)\n",
        "            with torch.no_grad():\n",
        "                embedded_series = embedder.embed(data_series).cpu()\n",
        "            # Stride over time-series\n",
        "            for i in range(0, data_series.size(0) - self.block_size + 1,\n",
        "                           self.stride):  # Truncate in block of block_size\n",
        "                data_series0 = embedded_series[i: i + self.block_size]\n",
        "                self.examples.append(data_series0)\n",
        "\n",
        "                if self.eval:\n",
        "                    self.states.append(data_series[i: i + self.block_size].cpu())\n",
        "\n",
        "            samples = samples + 1\n",
        "            if (self.ndata > 0 and samples >= self.ndata):  # If we have enough time-series samples break loop\n",
        "                break\n",
        "        \n",
        "        logger.info(\n",
        "            'Collected {:d} time-series from hdf5 file. Total of {:d} time-series.'.format(samples, len(self.examples))\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j396PtYzV_S1"
      },
      "source": [
        "## Initalizing Config and Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcpC9Fy243RN",
        "outputId": "d5b1b4cf-70c3-4fbf-98e3-9555de3a3a38"
      },
      "source": [
        "# Parse arguments using the hugging face argument parser\n",
        "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
        "model_args, data_args, training_args = parser.parse_args_into_dataclasses(argv)\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN)\n",
        "# Configure arguments after intialization \n",
        "model_args, data_args, training_args = ArgUtils.config(model_args, data_args, training_args)\n",
        "\n",
        "# Rossler configuration\n",
        "config = RosslerConfig()\n",
        "# Load embedding model\n",
        "embedding_model = RosslerEmbedding(config).to(training_args.src_device)\n",
        "embedding_model.load_model(model_args.embedding_file_or_path)\n",
        "\n",
        "# Load visualization utility class\n",
        "viz = RosslerViz(training_args.plot_dir)\n",
        "\n",
        "# Init transformer model\n",
        "transformer = PhysformerGPT2(config, model_args.model_name)\n",
        "model  = PhysformerTrain(config, transformer)\n",
        "if(training_args.epoch_start > 0):\n",
        "    model.load_model(training_args.ckpt_dir, epoch=training_args.epoch_start)\n",
        "if(model_args.transformer_file_or_path):\n",
        "    model.load_model(model_args.transformer_file_or_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/28/2021 22:48:53 - WARNING - trphysx.config.args -   Selected init name not in built-in models. Be careful.\n",
            "07/28/2021 22:48:53 - INFO - root -   Using a single GPU for training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of embedding parameters: 36249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/28/2021 22:48:56 - INFO - trphysx.embedding.embedding_model -   Loading embedding model from file: ./embedding_rossler300.pth\n",
            "07/28/2021 22:48:56 - INFO - trphysx.transformer.phys_transformer_gpt2 -   Number of parameters: 52960\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYAA52lXViUr"
      },
      "source": [
        "## Creating Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auDiMVZ5UfNz"
      },
      "source": [
        "Next create the training and validation datasets. This will probably take a little bit. We need to compute the embedded representations for the transformer for each example. Forcunately, assuming your embedding model has not changed or block size, the dataset will be locally cached allowing for fast reloading in the future. Use the \"overwrite_cache\" argument to force a new dataset creation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnrtuKdhGuWQ",
        "outputId": "6e1ec8a9-bc76-4e1e-d67f-3bc0d0ab6cd1"
      },
      "source": [
        "# Initialize training and validation datasets\n",
        "training_data = RosslerDataset(\n",
        "    embedding_model, \n",
        "    data_args.training_h5_file, \n",
        "    block_size=config.n_ctx, \n",
        "    stride=data_args.stride,\n",
        "    ndata=data_args.n_train, \n",
        "    overwrite_cache=data_args.overwrite_cache)\n",
        "\n",
        "eval_data = RosslerDataset(\n",
        "    embedding_model, \n",
        "    data_args.eval_h5_file, \n",
        "    block_size=256,\n",
        "    stride=1024,\n",
        "    ndata=data_args.n_eval, \n",
        "    eval = True,\n",
        "    overwrite_cache=data_args.overwrite_cache)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/28/2021 22:48:56 - INFO - filelock -   Lock 140269747205520 acquired on ./data/cached2048_RosslerEmbedding_32_rossler_training.hdf5.lock\n",
            "07/28/2021 22:48:56 - INFO - trphysx.data_utils.dataset_phys -   Creating features from dataset file at ./data\n",
            "07/28/2021 22:49:12 - INFO - __main__ -   Collected 256 time-series from hdf5 file. Total of 16128 time-series.\n",
            "07/28/2021 22:49:35 - INFO - trphysx.data_utils.dataset_phys -   Saving features into cached file ./data/cached2048_RosslerEmbedding_32_rossler_training.hdf5 [took 23.182 s]\n",
            "07/28/2021 22:49:35 - INFO - filelock -   Lock 140269747205520 released on ./data/cached2048_RosslerEmbedding_32_rossler_training.hdf5.lock\n",
            "07/28/2021 22:49:35 - INFO - filelock -   Lock 140269753473616 acquired on ./data/cached32_RosslerEmbedding_256_rossler_valid.hdf5.lock\n",
            "07/28/2021 22:49:35 - INFO - trphysx.data_utils.dataset_phys -   Loading features from cached file ./data/cached32_RosslerEmbedding_256_rossler_valid.hdf5 [took 0.013 s]\n",
            "07/28/2021 22:49:35 - INFO - filelock -   Lock 140269753473616 released on ./data/cached32_RosslerEmbedding_256_rossler_valid.hdf5.lock\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yKpYWniHP1D"
      },
      "source": [
        "Initialize the optimizer and scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2x1UHjRHTQ3"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=training_args.lr, weight_decay=1e-8)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 14, 2, eta_min=1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFNXGEaoVovI"
      },
      "source": [
        "## Training the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUUQltYpHbT-"
      },
      "source": [
        "Create training class and train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwp3oOjRHd6j",
        "outputId": "95df3579-82ad-4599-9032-c51af61b2b25"
      },
      "source": [
        "trainer = Trainer(\n",
        "        model, \n",
        "        training_args, \n",
        "        (optimizer, scheduler), \n",
        "        train_dataset = training_data, \n",
        "        eval_dataset = eval_data, \n",
        "        embedding_model = embedding_model,\n",
        "        viz=viz)\n",
        "    \n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/28/2021 22:49:39 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00095\n",
            "07/28/2021 22:49:39 - INFO - trphysx.utils.trainer -   Epoch 1: Training loss 0.12158\n",
            "07/28/2021 22:49:39 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00095\n",
            "07/28/2021 22:49:39 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:49:43 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.49, State error: 34.50\n",
            "07/28/2021 22:49:43 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:49:47 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00089\n",
            "07/28/2021 22:49:47 - INFO - trphysx.utils.trainer -   Epoch 2: Training loss 0.00253\n",
            "07/28/2021 22:49:52 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00081\n",
            "07/28/2021 22:49:52 - INFO - trphysx.utils.trainer -   Epoch 3: Training loss 0.00130\n",
            "07/28/2021 22:49:56 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00072\n",
            "07/28/2021 22:49:56 - INFO - trphysx.utils.trainer -   Epoch 4: Training loss 0.00084\n",
            "07/28/2021 22:50:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00061\n",
            "07/28/2021 22:50:00 - INFO - trphysx.utils.trainer -   Epoch 5: Training loss 0.00061\n",
            "07/28/2021 22:50:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00050\n",
            "07/28/2021 22:50:04 - INFO - trphysx.utils.trainer -   Epoch 6: Training loss 0.00051\n",
            "07/28/2021 22:50:08 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00039\n",
            "07/28/2021 22:50:08 - INFO - trphysx.utils.trainer -   Epoch 7: Training loss 0.00044\n",
            "07/28/2021 22:50:13 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00028\n",
            "07/28/2021 22:50:13 - INFO - trphysx.utils.trainer -   Epoch 8: Training loss 0.00039\n",
            "07/28/2021 22:50:17 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00019\n",
            "07/28/2021 22:50:17 - INFO - trphysx.utils.trainer -   Epoch 9: Training loss 0.00035\n",
            "07/28/2021 22:50:22 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00011\n",
            "07/28/2021 22:50:22 - INFO - trphysx.utils.trainer -   Epoch 10: Training loss 0.00032\n",
            "07/28/2021 22:50:26 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00005\n",
            "07/28/2021 22:50:26 - INFO - trphysx.utils.trainer -   Epoch 11: Training loss 0.00030\n",
            "07/28/2021 22:50:31 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00001\n",
            "07/28/2021 22:50:31 - INFO - trphysx.utils.trainer -   Epoch 12: Training loss 0.00030\n",
            "07/28/2021 22:50:35 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:50:35 - INFO - trphysx.utils.trainer -   Epoch 13: Training loss 0.00029\n",
            "07/28/2021 22:50:39 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:50:39 - INFO - trphysx.utils.trainer -   Epoch 14: Training loss 0.00129\n",
            "07/28/2021 22:50:42 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:50:42 - INFO - trphysx.utils.trainer -   Epoch 15: Training loss 0.00027\n",
            "07/28/2021 22:50:46 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00097\n",
            "07/28/2021 22:50:46 - INFO - trphysx.utils.trainer -   Epoch 16: Training loss 0.00025\n",
            "07/28/2021 22:50:50 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00095\n",
            "07/28/2021 22:50:50 - INFO - trphysx.utils.trainer -   Epoch 17: Training loss 0.00024\n",
            "07/28/2021 22:50:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00092\n",
            "07/28/2021 22:50:53 - INFO - trphysx.utils.trainer -   Epoch 18: Training loss 0.00020\n",
            "07/28/2021 22:50:57 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00089\n",
            "07/28/2021 22:50:57 - INFO - trphysx.utils.trainer -   Epoch 19: Training loss 0.00021\n",
            "07/28/2021 22:51:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00085\n",
            "07/28/2021 22:51:00 - INFO - trphysx.utils.trainer -   Epoch 20: Training loss 0.00017\n",
            "07/28/2021 22:51:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00081\n",
            "07/28/2021 22:51:04 - INFO - trphysx.utils.trainer -   Epoch 21: Training loss 0.00017\n",
            "07/28/2021 22:51:08 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00077\n",
            "07/28/2021 22:51:08 - INFO - trphysx.utils.trainer -   Epoch 22: Training loss 0.00015\n",
            "07/28/2021 22:51:12 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00072\n",
            "07/28/2021 22:51:12 - INFO - trphysx.utils.trainer -   Epoch 23: Training loss 0.00015\n",
            "07/28/2021 22:51:15 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00067\n",
            "07/28/2021 22:51:15 - INFO - trphysx.utils.trainer -   Epoch 24: Training loss 0.00015\n",
            "07/28/2021 22:51:19 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00061\n",
            "07/28/2021 22:51:19 - INFO - trphysx.utils.trainer -   Epoch 25: Training loss 0.00013\n",
            "07/28/2021 22:51:19 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00061\n",
            "07/28/2021 22:51:19 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:51:24 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.22, State error: 21.67\n",
            "07/28/2021 22:51:24 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:51:27 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00056\n",
            "07/28/2021 22:51:27 - INFO - trphysx.utils.trainer -   Epoch 26: Training loss 0.00012\n",
            "07/28/2021 22:51:31 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00050\n",
            "07/28/2021 22:51:31 - INFO - trphysx.utils.trainer -   Epoch 27: Training loss 0.00013\n",
            "07/28/2021 22:51:34 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00044\n",
            "07/28/2021 22:51:34 - INFO - trphysx.utils.trainer -   Epoch 28: Training loss 0.00012\n",
            "07/28/2021 22:51:38 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00039\n",
            "07/28/2021 22:51:38 - INFO - trphysx.utils.trainer -   Epoch 29: Training loss 0.00011\n",
            "07/28/2021 22:51:41 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00034\n",
            "07/28/2021 22:51:41 - INFO - trphysx.utils.trainer -   Epoch 30: Training loss 0.00011\n",
            "07/28/2021 22:51:45 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00028\n",
            "07/28/2021 22:51:45 - INFO - trphysx.utils.trainer -   Epoch 31: Training loss 0.00011\n",
            "07/28/2021 22:51:48 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00023\n",
            "07/28/2021 22:51:48 - INFO - trphysx.utils.trainer -   Epoch 32: Training loss 0.00010\n",
            "07/28/2021 22:51:52 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00019\n",
            "07/28/2021 22:51:52 - INFO - trphysx.utils.trainer -   Epoch 33: Training loss 0.00010\n",
            "07/28/2021 22:51:55 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00015\n",
            "07/28/2021 22:51:55 - INFO - trphysx.utils.trainer -   Epoch 34: Training loss 0.00010\n",
            "07/28/2021 22:51:59 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00011\n",
            "07/28/2021 22:51:59 - INFO - trphysx.utils.trainer -   Epoch 35: Training loss 0.00010\n",
            "07/28/2021 22:52:02 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00008\n",
            "07/28/2021 22:52:02 - INFO - trphysx.utils.trainer -   Epoch 36: Training loss 0.00010\n",
            "07/28/2021 22:52:06 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00005\n",
            "07/28/2021 22:52:06 - INFO - trphysx.utils.trainer -   Epoch 37: Training loss 0.00010\n",
            "07/28/2021 22:52:09 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00003\n",
            "07/28/2021 22:52:09 - INFO - trphysx.utils.trainer -   Epoch 38: Training loss 0.00010\n",
            "07/28/2021 22:52:13 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00001\n",
            "07/28/2021 22:52:13 - INFO - trphysx.utils.trainer -   Epoch 39: Training loss 0.00010\n",
            "07/28/2021 22:52:17 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:52:17 - INFO - trphysx.utils.trainer -   Epoch 40: Training loss 0.00010\n",
            "07/28/2021 22:52:21 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:52:21 - INFO - trphysx.utils.trainer -   Epoch 41: Training loss 0.00009\n",
            "07/28/2021 22:52:24 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:52:24 - INFO - trphysx.utils.trainer -   Epoch 42: Training loss 0.00118\n",
            "07/28/2021 22:52:28 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:52:28 - INFO - trphysx.utils.trainer -   Epoch 43: Training loss 0.00012\n",
            "07/28/2021 22:52:32 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:52:32 - INFO - trphysx.utils.trainer -   Epoch 44: Training loss 0.00012\n",
            "07/28/2021 22:52:35 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:52:35 - INFO - trphysx.utils.trainer -   Epoch 45: Training loss 0.00013\n",
            "07/28/2021 22:52:39 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00098\n",
            "07/28/2021 22:52:39 - INFO - trphysx.utils.trainer -   Epoch 46: Training loss 0.00010\n",
            "07/28/2021 22:52:42 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00097\n",
            "07/28/2021 22:52:42 - INFO - trphysx.utils.trainer -   Epoch 47: Training loss 0.00011\n",
            "07/28/2021 22:52:46 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00096\n",
            "07/28/2021 22:52:46 - INFO - trphysx.utils.trainer -   Epoch 48: Training loss 0.00012\n",
            "07/28/2021 22:52:49 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00095\n",
            "07/28/2021 22:52:49 - INFO - trphysx.utils.trainer -   Epoch 49: Training loss 0.00009\n",
            "07/28/2021 22:52:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00094\n",
            "07/28/2021 22:52:53 - INFO - trphysx.utils.trainer -   Epoch 50: Training loss 0.00010\n",
            "07/28/2021 22:52:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00094\n",
            "07/28/2021 22:52:53 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:52:57 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.53, State error: 47.05\n",
            "07/28/2021 22:52:57 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:53:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00092\n",
            "07/28/2021 22:53:00 - INFO - trphysx.utils.trainer -   Epoch 51: Training loss 0.00010\n",
            "07/28/2021 22:53:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00091\n",
            "07/28/2021 22:53:04 - INFO - trphysx.utils.trainer -   Epoch 52: Training loss 0.00010\n",
            "07/28/2021 22:53:07 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00089\n",
            "07/28/2021 22:53:07 - INFO - trphysx.utils.trainer -   Epoch 53: Training loss 0.00009\n",
            "07/28/2021 22:53:11 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00087\n",
            "07/28/2021 22:53:11 - INFO - trphysx.utils.trainer -   Epoch 54: Training loss 0.00010\n",
            "07/28/2021 22:53:15 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00085\n",
            "07/28/2021 22:53:15 - INFO - trphysx.utils.trainer -   Epoch 55: Training loss 0.00010\n",
            "07/28/2021 22:53:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00083\n",
            "07/28/2021 22:53:18 - INFO - trphysx.utils.trainer -   Epoch 56: Training loss 0.00008\n",
            "07/28/2021 22:53:22 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00081\n",
            "07/28/2021 22:53:22 - INFO - trphysx.utils.trainer -   Epoch 57: Training loss 0.00008\n",
            "07/28/2021 22:53:26 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00079\n",
            "07/28/2021 22:53:26 - INFO - trphysx.utils.trainer -   Epoch 58: Training loss 0.00009\n",
            "07/28/2021 22:53:30 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00077\n",
            "07/28/2021 22:53:30 - INFO - trphysx.utils.trainer -   Epoch 59: Training loss 0.00008\n",
            "07/28/2021 22:53:33 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00074\n",
            "07/28/2021 22:53:33 - INFO - trphysx.utils.trainer -   Epoch 60: Training loss 0.00008\n",
            "07/28/2021 22:53:37 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00072\n",
            "07/28/2021 22:53:37 - INFO - trphysx.utils.trainer -   Epoch 61: Training loss 0.00008\n",
            "07/28/2021 22:53:41 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00069\n",
            "07/28/2021 22:53:41 - INFO - trphysx.utils.trainer -   Epoch 62: Training loss 0.00008\n",
            "07/28/2021 22:53:44 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00067\n",
            "07/28/2021 22:53:44 - INFO - trphysx.utils.trainer -   Epoch 63: Training loss 0.00008\n",
            "07/28/2021 22:53:48 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00064\n",
            "07/28/2021 22:53:48 - INFO - trphysx.utils.trainer -   Epoch 64: Training loss 0.00008\n",
            "07/28/2021 22:53:51 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00061\n",
            "07/28/2021 22:53:51 - INFO - trphysx.utils.trainer -   Epoch 65: Training loss 0.00007\n",
            "07/28/2021 22:53:55 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00058\n",
            "07/28/2021 22:53:55 - INFO - trphysx.utils.trainer -   Epoch 66: Training loss 0.00007\n",
            "07/28/2021 22:53:58 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00056\n",
            "07/28/2021 22:53:58 - INFO - trphysx.utils.trainer -   Epoch 67: Training loss 0.00006\n",
            "07/28/2021 22:54:02 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00053\n",
            "07/28/2021 22:54:02 - INFO - trphysx.utils.trainer -   Epoch 68: Training loss 0.00006\n",
            "07/28/2021 22:54:05 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00050\n",
            "07/28/2021 22:54:05 - INFO - trphysx.utils.trainer -   Epoch 69: Training loss 0.00007\n",
            "07/28/2021 22:54:09 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00047\n",
            "07/28/2021 22:54:09 - INFO - trphysx.utils.trainer -   Epoch 70: Training loss 0.00006\n",
            "07/28/2021 22:54:12 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00044\n",
            "07/28/2021 22:54:12 - INFO - trphysx.utils.trainer -   Epoch 71: Training loss 0.00006\n",
            "07/28/2021 22:54:16 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00042\n",
            "07/28/2021 22:54:16 - INFO - trphysx.utils.trainer -   Epoch 72: Training loss 0.00006\n",
            "07/28/2021 22:54:19 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00039\n",
            "07/28/2021 22:54:19 - INFO - trphysx.utils.trainer -   Epoch 73: Training loss 0.00006\n",
            "07/28/2021 22:54:23 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00036\n",
            "07/28/2021 22:54:23 - INFO - trphysx.utils.trainer -   Epoch 74: Training loss 0.00006\n",
            "07/28/2021 22:54:27 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00033\n",
            "07/28/2021 22:54:27 - INFO - trphysx.utils.trainer -   Epoch 75: Training loss 0.00005\n",
            "07/28/2021 22:54:27 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00033\n",
            "07/28/2021 22:54:27 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:54:31 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.22, State error: 25.59\n",
            "07/28/2021 22:54:31 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:54:35 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00031\n",
            "07/28/2021 22:54:35 - INFO - trphysx.utils.trainer -   Epoch 76: Training loss 0.00005\n",
            "07/28/2021 22:54:39 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00028\n",
            "07/28/2021 22:54:39 - INFO - trphysx.utils.trainer -   Epoch 77: Training loss 0.00005\n",
            "07/28/2021 22:54:42 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00026\n",
            "07/28/2021 22:54:42 - INFO - trphysx.utils.trainer -   Epoch 78: Training loss 0.00005\n",
            "07/28/2021 22:54:46 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00023\n",
            "07/28/2021 22:54:46 - INFO - trphysx.utils.trainer -   Epoch 79: Training loss 0.00005\n",
            "07/28/2021 22:54:50 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00021\n",
            "07/28/2021 22:54:50 - INFO - trphysx.utils.trainer -   Epoch 80: Training loss 0.00005\n",
            "07/28/2021 22:54:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00019\n",
            "07/28/2021 22:54:53 - INFO - trphysx.utils.trainer -   Epoch 81: Training loss 0.00005\n",
            "07/28/2021 22:54:57 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00017\n",
            "07/28/2021 22:54:57 - INFO - trphysx.utils.trainer -   Epoch 82: Training loss 0.00005\n",
            "07/28/2021 22:55:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00015\n",
            "07/28/2021 22:55:00 - INFO - trphysx.utils.trainer -   Epoch 83: Training loss 0.00005\n",
            "07/28/2021 22:55:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00013\n",
            "07/28/2021 22:55:04 - INFO - trphysx.utils.trainer -   Epoch 84: Training loss 0.00005\n",
            "07/28/2021 22:55:07 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00011\n",
            "07/28/2021 22:55:07 - INFO - trphysx.utils.trainer -   Epoch 85: Training loss 0.00005\n",
            "07/28/2021 22:55:11 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00009\n",
            "07/28/2021 22:55:11 - INFO - trphysx.utils.trainer -   Epoch 86: Training loss 0.00005\n",
            "07/28/2021 22:55:14 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00008\n",
            "07/28/2021 22:55:14 - INFO - trphysx.utils.trainer -   Epoch 87: Training loss 0.00005\n",
            "07/28/2021 22:55:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00006\n",
            "07/28/2021 22:55:18 - INFO - trphysx.utils.trainer -   Epoch 88: Training loss 0.00005\n",
            "07/28/2021 22:55:21 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00005\n",
            "07/28/2021 22:55:21 - INFO - trphysx.utils.trainer -   Epoch 89: Training loss 0.00005\n",
            "07/28/2021 22:55:25 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00004\n",
            "07/28/2021 22:55:25 - INFO - trphysx.utils.trainer -   Epoch 90: Training loss 0.00005\n",
            "07/28/2021 22:55:29 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00003\n",
            "07/28/2021 22:55:29 - INFO - trphysx.utils.trainer -   Epoch 91: Training loss 0.00004\n",
            "07/28/2021 22:55:32 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00002\n",
            "07/28/2021 22:55:32 - INFO - trphysx.utils.trainer -   Epoch 92: Training loss 0.00004\n",
            "07/28/2021 22:55:36 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00001\n",
            "07/28/2021 22:55:36 - INFO - trphysx.utils.trainer -   Epoch 93: Training loss 0.00004\n",
            "07/28/2021 22:55:40 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00001\n",
            "07/28/2021 22:55:40 - INFO - trphysx.utils.trainer -   Epoch 94: Training loss 0.00004\n",
            "07/28/2021 22:55:44 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:55:44 - INFO - trphysx.utils.trainer -   Epoch 95: Training loss 0.00004\n",
            "07/28/2021 22:55:47 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:55:47 - INFO - trphysx.utils.trainer -   Epoch 96: Training loss 0.00004\n",
            "07/28/2021 22:55:51 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00000\n",
            "07/28/2021 22:55:51 - INFO - trphysx.utils.trainer -   Epoch 97: Training loss 0.00004\n",
            "07/28/2021 22:55:55 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:55:55 - INFO - trphysx.utils.trainer -   Epoch 98: Training loss 0.00089\n",
            "07/28/2021 22:55:58 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:55:58 - INFO - trphysx.utils.trainer -   Epoch 99: Training loss 0.00006\n",
            "07/28/2021 22:56:02 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:56:02 - INFO - trphysx.utils.trainer -   Epoch 100: Training loss 0.00006\n",
            "07/28/2021 22:56:02 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:56:02 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:56:06 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.14, State error: 9.03\n",
            "07/28/2021 22:56:06 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:56:09 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:56:09 - INFO - trphysx.utils.trainer -   Epoch 101: Training loss 0.00006\n",
            "07/28/2021 22:56:13 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00100\n",
            "07/28/2021 22:56:13 - INFO - trphysx.utils.trainer -   Epoch 102: Training loss 0.00006\n",
            "07/28/2021 22:56:16 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:56:16 - INFO - trphysx.utils.trainer -   Epoch 103: Training loss 0.00006\n",
            "07/28/2021 22:56:20 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:56:20 - INFO - trphysx.utils.trainer -   Epoch 104: Training loss 0.00006\n",
            "07/28/2021 22:56:23 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00099\n",
            "07/28/2021 22:56:23 - INFO - trphysx.utils.trainer -   Epoch 105: Training loss 0.00007\n",
            "07/28/2021 22:56:27 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00098\n",
            "07/28/2021 22:56:27 - INFO - trphysx.utils.trainer -   Epoch 106: Training loss 0.00005\n",
            "07/28/2021 22:56:30 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00098\n",
            "07/28/2021 22:56:30 - INFO - trphysx.utils.trainer -   Epoch 107: Training loss 0.00006\n",
            "07/28/2021 22:56:34 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00098\n",
            "07/28/2021 22:56:34 - INFO - trphysx.utils.trainer -   Epoch 108: Training loss 0.00006\n",
            "07/28/2021 22:56:38 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00097\n",
            "07/28/2021 22:56:38 - INFO - trphysx.utils.trainer -   Epoch 109: Training loss 0.00006\n",
            "07/28/2021 22:56:42 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00097\n",
            "07/28/2021 22:56:42 - INFO - trphysx.utils.trainer -   Epoch 110: Training loss 0.00006\n",
            "07/28/2021 22:56:46 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00096\n",
            "07/28/2021 22:56:46 - INFO - trphysx.utils.trainer -   Epoch 111: Training loss 0.00006\n",
            "07/28/2021 22:56:49 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00096\n",
            "07/28/2021 22:56:49 - INFO - trphysx.utils.trainer -   Epoch 112: Training loss 0.00005\n",
            "07/28/2021 22:56:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00095\n",
            "07/28/2021 22:56:53 - INFO - trphysx.utils.trainer -   Epoch 113: Training loss 0.00007\n",
            "07/28/2021 22:56:57 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00094\n",
            "07/28/2021 22:56:57 - INFO - trphysx.utils.trainer -   Epoch 114: Training loss 0.00005\n",
            "07/28/2021 22:57:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00094\n",
            "07/28/2021 22:57:00 - INFO - trphysx.utils.trainer -   Epoch 115: Training loss 0.00006\n",
            "07/28/2021 22:57:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00093\n",
            "07/28/2021 22:57:04 - INFO - trphysx.utils.trainer -   Epoch 116: Training loss 0.00005\n",
            "07/28/2021 22:57:07 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00092\n",
            "07/28/2021 22:57:07 - INFO - trphysx.utils.trainer -   Epoch 117: Training loss 0.00006\n",
            "07/28/2021 22:57:11 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00092\n",
            "07/28/2021 22:57:11 - INFO - trphysx.utils.trainer -   Epoch 118: Training loss 0.00004\n",
            "07/28/2021 22:57:15 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00091\n",
            "07/28/2021 22:57:15 - INFO - trphysx.utils.trainer -   Epoch 119: Training loss 0.00005\n",
            "07/28/2021 22:57:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00090\n",
            "07/28/2021 22:57:18 - INFO - trphysx.utils.trainer -   Epoch 120: Training loss 0.00005\n",
            "07/28/2021 22:57:22 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00089\n",
            "07/28/2021 22:57:22 - INFO - trphysx.utils.trainer -   Epoch 121: Training loss 0.00005\n",
            "07/28/2021 22:57:26 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00088\n",
            "07/28/2021 22:57:26 - INFO - trphysx.utils.trainer -   Epoch 122: Training loss 0.00006\n",
            "07/28/2021 22:57:29 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00087\n",
            "07/28/2021 22:57:29 - INFO - trphysx.utils.trainer -   Epoch 123: Training loss 0.00005\n",
            "07/28/2021 22:57:33 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00086\n",
            "07/28/2021 22:57:33 - INFO - trphysx.utils.trainer -   Epoch 124: Training loss 0.00005\n",
            "07/28/2021 22:57:36 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00085\n",
            "07/28/2021 22:57:36 - INFO - trphysx.utils.trainer -   Epoch 125: Training loss 0.00004\n",
            "07/28/2021 22:57:36 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00085\n",
            "07/28/2021 22:57:36 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:57:40 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.15, State error: 17.42\n",
            "07/28/2021 22:57:40 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:57:44 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00084\n",
            "07/28/2021 22:57:44 - INFO - trphysx.utils.trainer -   Epoch 126: Training loss 0.00005\n",
            "07/28/2021 22:57:47 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00083\n",
            "07/28/2021 22:57:47 - INFO - trphysx.utils.trainer -   Epoch 127: Training loss 0.00004\n",
            "07/28/2021 22:57:51 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00082\n",
            "07/28/2021 22:57:51 - INFO - trphysx.utils.trainer -   Epoch 128: Training loss 0.00005\n",
            "07/28/2021 22:57:54 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00081\n",
            "07/28/2021 22:57:54 - INFO - trphysx.utils.trainer -   Epoch 129: Training loss 0.00005\n",
            "07/28/2021 22:57:58 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00080\n",
            "07/28/2021 22:57:58 - INFO - trphysx.utils.trainer -   Epoch 130: Training loss 0.00004\n",
            "07/28/2021 22:58:01 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00079\n",
            "07/28/2021 22:58:01 - INFO - trphysx.utils.trainer -   Epoch 131: Training loss 0.00004\n",
            "07/28/2021 22:58:05 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00078\n",
            "07/28/2021 22:58:05 - INFO - trphysx.utils.trainer -   Epoch 132: Training loss 0.00004\n",
            "07/28/2021 22:58:08 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00077\n",
            "07/28/2021 22:58:08 - INFO - trphysx.utils.trainer -   Epoch 133: Training loss 0.00005\n",
            "07/28/2021 22:58:12 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00075\n",
            "07/28/2021 22:58:12 - INFO - trphysx.utils.trainer -   Epoch 134: Training loss 0.00004\n",
            "07/28/2021 22:58:16 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00074\n",
            "07/28/2021 22:58:16 - INFO - trphysx.utils.trainer -   Epoch 135: Training loss 0.00004\n",
            "07/28/2021 22:58:19 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00073\n",
            "07/28/2021 22:58:19 - INFO - trphysx.utils.trainer -   Epoch 136: Training loss 0.00004\n",
            "07/28/2021 22:58:23 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00072\n",
            "07/28/2021 22:58:23 - INFO - trphysx.utils.trainer -   Epoch 137: Training loss 0.00004\n",
            "07/28/2021 22:58:27 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00070\n",
            "07/28/2021 22:58:27 - INFO - trphysx.utils.trainer -   Epoch 138: Training loss 0.00004\n",
            "07/28/2021 22:58:30 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00069\n",
            "07/28/2021 22:58:30 - INFO - trphysx.utils.trainer -   Epoch 139: Training loss 0.00004\n",
            "07/28/2021 22:58:34 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00068\n",
            "07/28/2021 22:58:34 - INFO - trphysx.utils.trainer -   Epoch 140: Training loss 0.00004\n",
            "07/28/2021 22:58:38 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00067\n",
            "07/28/2021 22:58:38 - INFO - trphysx.utils.trainer -   Epoch 141: Training loss 0.00004\n",
            "07/28/2021 22:58:41 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00065\n",
            "07/28/2021 22:58:41 - INFO - trphysx.utils.trainer -   Epoch 142: Training loss 0.00004\n",
            "07/28/2021 22:58:45 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00064\n",
            "07/28/2021 22:58:45 - INFO - trphysx.utils.trainer -   Epoch 143: Training loss 0.00004\n",
            "07/28/2021 22:58:48 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00062\n",
            "07/28/2021 22:58:48 - INFO - trphysx.utils.trainer -   Epoch 144: Training loss 0.00004\n",
            "07/28/2021 22:58:52 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00061\n",
            "07/28/2021 22:58:52 - INFO - trphysx.utils.trainer -   Epoch 145: Training loss 0.00003\n",
            "07/28/2021 22:58:55 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00060\n",
            "07/28/2021 22:58:55 - INFO - trphysx.utils.trainer -   Epoch 146: Training loss 0.00003\n",
            "07/28/2021 22:58:59 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00058\n",
            "07/28/2021 22:58:59 - INFO - trphysx.utils.trainer -   Epoch 147: Training loss 0.00004\n",
            "07/28/2021 22:59:03 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00057\n",
            "07/28/2021 22:59:03 - INFO - trphysx.utils.trainer -   Epoch 148: Training loss 0.00004\n",
            "07/28/2021 22:59:06 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00056\n",
            "07/28/2021 22:59:06 - INFO - trphysx.utils.trainer -   Epoch 149: Training loss 0.00004\n",
            "07/28/2021 22:59:10 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00054\n",
            "07/28/2021 22:59:10 - INFO - trphysx.utils.trainer -   Epoch 150: Training loss 0.00003\n",
            "07/28/2021 22:59:10 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00054\n",
            "07/28/2021 22:59:10 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 22:59:13 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.36, State error: 28.05\n",
            "07/28/2021 22:59:13 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 22:59:17 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00053\n",
            "07/28/2021 22:59:17 - INFO - trphysx.utils.trainer -   Epoch 151: Training loss 0.00004\n",
            "07/28/2021 22:59:21 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00051\n",
            "07/28/2021 22:59:21 - INFO - trphysx.utils.trainer -   Epoch 152: Training loss 0.00003\n",
            "07/28/2021 22:59:25 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00050\n",
            "07/28/2021 22:59:25 - INFO - trphysx.utils.trainer -   Epoch 153: Training loss 0.00003\n",
            "07/28/2021 22:59:28 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00049\n",
            "07/28/2021 22:59:28 - INFO - trphysx.utils.trainer -   Epoch 154: Training loss 0.00003\n",
            "07/28/2021 22:59:32 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00047\n",
            "07/28/2021 22:59:32 - INFO - trphysx.utils.trainer -   Epoch 155: Training loss 0.00003\n",
            "07/28/2021 22:59:36 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00046\n",
            "07/28/2021 22:59:36 - INFO - trphysx.utils.trainer -   Epoch 156: Training loss 0.00003\n",
            "07/28/2021 22:59:40 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00044\n",
            "07/28/2021 22:59:40 - INFO - trphysx.utils.trainer -   Epoch 157: Training loss 0.00003\n",
            "07/28/2021 22:59:43 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00043\n",
            "07/28/2021 22:59:43 - INFO - trphysx.utils.trainer -   Epoch 158: Training loss 0.00003\n",
            "07/28/2021 22:59:47 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00042\n",
            "07/28/2021 22:59:47 - INFO - trphysx.utils.trainer -   Epoch 159: Training loss 0.00003\n",
            "07/28/2021 22:59:50 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00040\n",
            "07/28/2021 22:59:50 - INFO - trphysx.utils.trainer -   Epoch 160: Training loss 0.00003\n",
            "07/28/2021 22:59:53 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00039\n",
            "07/28/2021 22:59:53 - INFO - trphysx.utils.trainer -   Epoch 161: Training loss 0.00003\n",
            "07/28/2021 22:59:57 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00038\n",
            "07/28/2021 22:59:57 - INFO - trphysx.utils.trainer -   Epoch 162: Training loss 0.00003\n",
            "07/28/2021 23:00:00 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00036\n",
            "07/28/2021 23:00:00 - INFO - trphysx.utils.trainer -   Epoch 163: Training loss 0.00003\n",
            "07/28/2021 23:00:04 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00035\n",
            "07/28/2021 23:00:04 - INFO - trphysx.utils.trainer -   Epoch 164: Training loss 0.00003\n",
            "07/28/2021 23:00:07 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00033\n",
            "07/28/2021 23:00:07 - INFO - trphysx.utils.trainer -   Epoch 165: Training loss 0.00003\n",
            "07/28/2021 23:00:11 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00032\n",
            "07/28/2021 23:00:11 - INFO - trphysx.utils.trainer -   Epoch 166: Training loss 0.00003\n",
            "07/28/2021 23:00:14 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00031\n",
            "07/28/2021 23:00:14 - INFO - trphysx.utils.trainer -   Epoch 167: Training loss 0.00003\n",
            "07/28/2021 23:00:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00030\n",
            "07/28/2021 23:00:18 - INFO - trphysx.utils.trainer -   Epoch 168: Training loss 0.00003\n",
            "07/28/2021 23:00:21 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00028\n",
            "07/28/2021 23:00:21 - INFO - trphysx.utils.trainer -   Epoch 169: Training loss 0.00003\n",
            "07/28/2021 23:00:25 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00027\n",
            "07/28/2021 23:00:25 - INFO - trphysx.utils.trainer -   Epoch 170: Training loss 0.00003\n",
            "07/28/2021 23:00:29 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00026\n",
            "07/28/2021 23:00:29 - INFO - trphysx.utils.trainer -   Epoch 171: Training loss 0.00003\n",
            "07/28/2021 23:00:32 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00025\n",
            "07/28/2021 23:00:32 - INFO - trphysx.utils.trainer -   Epoch 172: Training loss 0.00003\n",
            "07/28/2021 23:00:36 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00023\n",
            "07/28/2021 23:00:36 - INFO - trphysx.utils.trainer -   Epoch 173: Training loss 0.00003\n",
            "07/28/2021 23:00:40 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00022\n",
            "07/28/2021 23:00:40 - INFO - trphysx.utils.trainer -   Epoch 174: Training loss 0.00003\n",
            "07/28/2021 23:00:43 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00021\n",
            "07/28/2021 23:00:43 - INFO - trphysx.utils.trainer -   Epoch 175: Training loss 0.00003\n",
            "07/28/2021 23:00:43 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00021\n",
            "07/28/2021 23:00:43 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 23:00:47 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.22, State error: 16.75\n",
            "07/28/2021 23:00:47 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n",
            "07/28/2021 23:00:51 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00020\n",
            "07/28/2021 23:00:51 - INFO - trphysx.utils.trainer -   Epoch 176: Training loss 0.00003\n",
            "07/28/2021 23:00:55 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00019\n",
            "07/28/2021 23:00:55 - INFO - trphysx.utils.trainer -   Epoch 177: Training loss 0.00003\n",
            "07/28/2021 23:00:58 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00018\n",
            "07/28/2021 23:00:58 - INFO - trphysx.utils.trainer -   Epoch 178: Training loss 0.00003\n",
            "07/28/2021 23:01:02 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00017\n",
            "07/28/2021 23:01:02 - INFO - trphysx.utils.trainer -   Epoch 179: Training loss 0.00003\n",
            "07/28/2021 23:01:05 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00016\n",
            "07/28/2021 23:01:05 - INFO - trphysx.utils.trainer -   Epoch 180: Training loss 0.00003\n",
            "07/28/2021 23:01:08 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00015\n",
            "07/28/2021 23:01:08 - INFO - trphysx.utils.trainer -   Epoch 181: Training loss 0.00003\n",
            "07/28/2021 23:01:12 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00014\n",
            "07/28/2021 23:01:12 - INFO - trphysx.utils.trainer -   Epoch 182: Training loss 0.00003\n",
            "07/28/2021 23:01:15 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00013\n",
            "07/28/2021 23:01:15 - INFO - trphysx.utils.trainer -   Epoch 183: Training loss 0.00003\n",
            "07/28/2021 23:01:19 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00012\n",
            "07/28/2021 23:01:19 - INFO - trphysx.utils.trainer -   Epoch 184: Training loss 0.00003\n",
            "07/28/2021 23:01:22 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00011\n",
            "07/28/2021 23:01:22 - INFO - trphysx.utils.trainer -   Epoch 185: Training loss 0.00002\n",
            "07/28/2021 23:01:26 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00010\n",
            "07/28/2021 23:01:26 - INFO - trphysx.utils.trainer -   Epoch 186: Training loss 0.00002\n",
            "07/28/2021 23:01:30 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00009\n",
            "07/28/2021 23:01:30 - INFO - trphysx.utils.trainer -   Epoch 187: Training loss 0.00002\n",
            "07/28/2021 23:01:33 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00008\n",
            "07/28/2021 23:01:33 - INFO - trphysx.utils.trainer -   Epoch 188: Training loss 0.00002\n",
            "07/28/2021 23:01:37 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00008\n",
            "07/28/2021 23:01:37 - INFO - trphysx.utils.trainer -   Epoch 189: Training loss 0.00002\n",
            "07/28/2021 23:01:41 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00007\n",
            "07/28/2021 23:01:41 - INFO - trphysx.utils.trainer -   Epoch 190: Training loss 0.00002\n",
            "07/28/2021 23:01:45 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00006\n",
            "07/28/2021 23:01:45 - INFO - trphysx.utils.trainer -   Epoch 191: Training loss 0.00002\n",
            "07/28/2021 23:01:48 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00006\n",
            "07/28/2021 23:01:48 - INFO - trphysx.utils.trainer -   Epoch 192: Training loss 0.00002\n",
            "07/28/2021 23:01:52 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00005\n",
            "07/28/2021 23:01:52 - INFO - trphysx.utils.trainer -   Epoch 193: Training loss 0.00002\n",
            "07/28/2021 23:01:56 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00004\n",
            "07/28/2021 23:01:56 - INFO - trphysx.utils.trainer -   Epoch 194: Training loss 0.00002\n",
            "07/28/2021 23:01:59 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00004\n",
            "07/28/2021 23:01:59 - INFO - trphysx.utils.trainer -   Epoch 195: Training loss 0.00002\n",
            "07/28/2021 23:02:03 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00003\n",
            "07/28/2021 23:02:03 - INFO - trphysx.utils.trainer -   Epoch 196: Training loss 0.00002\n",
            "07/28/2021 23:02:07 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00003\n",
            "07/28/2021 23:02:07 - INFO - trphysx.utils.trainer -   Epoch 197: Training loss 0.00002\n",
            "07/28/2021 23:02:10 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00002\n",
            "07/28/2021 23:02:10 - INFO - trphysx.utils.trainer -   Epoch 198: Training loss 0.00002\n",
            "07/28/2021 23:02:14 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00002\n",
            "07/28/2021 23:02:14 - INFO - trphysx.utils.trainer -   Epoch 199: Training loss 0.00002\n",
            "07/28/2021 23:02:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00002\n",
            "07/28/2021 23:02:18 - INFO - trphysx.utils.trainer -   Epoch 200: Training loss 0.00002\n",
            "07/28/2021 23:02:18 - INFO - trphysx.utils.trainer -   Current Learning rate: 0.00002\n",
            "07/28/2021 23:02:18 - INFO - trphysx.utils.trainer -   Evaluating...\n",
            "07/28/2021 23:02:23 - INFO - trphysx.utils.trainer -   Eval embedding error: 0.25, State error: 23.33\n",
            "07/28/2021 23:02:23 - INFO - trphysx.utils.trainer -   Checkpointing model, optimizer and scheduler.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlYEwSe6WHoF"
      },
      "source": [
        "## Visualization of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2K4s1xAXAA6"
      },
      "source": [
        "We will just embed a few of the test prediction for several epochs. For this particular attractor, it can be hit or miss because of the chaotic jumps on the z-axis. Both the embedding model and transformer training can be further fine tuned. More can be viewed in the outputs folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w7J5GgEFh_8t",
        "outputId": "2d67b62f-77e9-4440-da5c-76132accb7b2"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "for epoch in [1, 50, 100, 150, 200]:\n",
        "  print('Validation prediction for epoch: {:d}'.format(epoch))\n",
        "  file_path = './outputs/transformer_rossler/ntrain2048_epochs200_batch64/viz/rosslerPred1_{:d}.png'.format(epoch)\n",
        "  display(Image(file_path, width=300, height=300))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Eq24CTk3Wlam"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}